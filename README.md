#  Sinyal Ä°ÅŸleme ve Makine Ã–ÄŸrenmesi : Ä°ki AÅŸamalÄ± Hibrit Ses TanÄ±ma Sistemi
###### Swipe down for English
Bu proje, TÃ¼rkÃ§e ve Ä°ngilizce dillerinde Ã§alÄ±ÅŸan, iki aÅŸamalÄ± kademeli (**Cascaded**) mimariye sahip geliÅŸmiÅŸ bir sesli komut tanÄ±ma sistemidir. Sistem, ham ses verisini gerÃ§ek zamanlÄ± iÅŸleyerek dÃ¼ÅŸÃ¼k gecikme sÃ¼resi ve yÃ¼ksek doÄŸrulukla akÄ±llÄ± ev komutlarÄ±nÄ± yerine getirir.

---

## Ã–ne Ã‡Ä±kan Ã–zellikler

* **Ã‡ift Dilli Destek (Bilingual):** TR ve EN dilleri iÃ§in optimize edilmiÅŸ hibrit modeller.
* **Ä°ki AÅŸamalÄ± Mimari (True Cascade):**
    * **Stage-1 (Neural Processing):** CNN (1D/2D) tabanlÄ± sliding-window sÄ±nÄ±flandÄ±rma. Ham veriden doÄŸrudan Ã¶znitelik Ã§Ä±karÄ±mÄ± yapar.
    * **Stage-2 (Decision Refinement):** Majority Voting ve Word2Vec tabanlÄ± NLP karar mekanizmasÄ±. Stage-1 Ã§Ä±ktÄ±larÄ±nÄ± rafine ederek gÃ¼rÃ¼ltÃ¼yÃ¼ ekarte eder.
* **Modern Dashboard:** KaranlÄ±k mod destekli, canlÄ± barlar ve timeline loglarÄ± iÃ§eren dinamik kullanÄ±cÄ± arayÃ¼zÃ¼.

---

## Teknik Ä°ÅŸlem HattÄ± (Pipeline)

Sistem, ses sinyalini nihai komuta dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in ÅŸu aÅŸamalardan geÃ§er:

1.  **Sinyal KoÅŸullandÄ±rma:** 100Hz-6000Hz Band-pass filtreleme, normalizasyon ve 0.1s padding uygulamasÄ±.
2.  **AÅŸama 1:** 1.0s pencere uzunluÄŸu ve 0.1s kaydÄ±rma (hop) ile CNN modelleri Ã¼zerinden Ã¶znitelik Ã§Ä±karÄ±mÄ± (MEL/MFCC).
3.  **AÅŸama 2:** Stage-1'den gelen tahminlerin birleÅŸtirilmesi. **Majority Voting** veya **NLP Cosine Similarity** (Word2Vec) kullanÄ±mÄ± ile nihai karar.
4.  **DeÄŸerlendirme:** Her iÅŸlem iÃ§in gerÃ§ek zamanlÄ± **Response Time (RT)** Ã¶lÃ§Ã¼mÃ¼ ve **Ranking Score** hesaplamasÄ±.

---

## BaÅŸarÄ± Metrikleri & SÄ±ralama PuanÄ±

Proje baÅŸarÄ±sÄ±, doÄŸruluk ve hÄ±zÄ±n optimize edildiÄŸi resmi sÄ±ralama formÃ¼lÃ¼ ile Ã¶lÃ§Ã¼lmektedir:

$$Score = \frac{Accuracy_{TR} \times Accuracy_{EN}}{ResponseTime_{TR} \times ResponseTime_{EN}}$$

* **Model EÄŸitim ProtokolÃ¼:** TÃ¼m modeller `Random Seed = 47` ve `%80-%20` stratified split protokolÃ¼ne uygun olarak eÄŸitilmiÅŸtir.
* **Performans:** Sistem, gerÃ§ek zamanlÄ± (real-time) kullanÄ±mda milisaniye seviyesinde gecikme (Response Time) ile Ã§alÄ±ÅŸmaktadÄ±r.

---

## Proje YapÄ±sÄ±

* `Dataset_For_CNN/`: EÄŸitim ve test iÃ§in kullanÄ±lan ses kayÄ±tlarÄ±.
* `models/`: EÄŸitilmiÅŸ CNN modelleri (.h5), scaler ve label encoder dosyalarÄ±.
* `results/`: Modellerin doÄŸruluk ve karmaÅŸÄ±klÄ±k metriklerini iÃ§eren CSV raporlarÄ±.
* `main_inference.py`: Dosya tabanlÄ± (Playback) analiz arayÃ¼zÃ¼.
* `main_realtime.py`: CanlÄ± mikrofon analiz arayÃ¼zÃ¼.

---

## Kurulum

Sistemi Ã§alÄ±ÅŸtÄ±rmak iÃ§in gerekli kÃ¼tÃ¼phaneler:
`pip install tensorflow keras librosa numpy pandas sounddevice joblib gensim scikit-learn`

---

## GeliÅŸtirici

* **ERDEM TOSUN**

# Signal Processing and Machine Learning : Cascaded Hybrid Voice Controller

This project is an advanced voice command recognition system featuring a two-stage **Cascaded** architecture, supporting both Turkish and English languages. The system processes raw audio in real-time to execute smart home commands with ultra-low latency and high precision.



---

##  Key Features

* **Bilingual Support:** Optimized hybrid models for both Turkish (TR) and English (EN).
* **Two-Stage Cascaded Architecture:**
    * **Stage-1 (Neural Processing):** CNN (1D/2D) based sliding-window classification. Performs direct feature extraction from raw audio signals.
    * **Stage-2 (Decision Refinement):** Majority Voting and Word2Vec-based NLP decision mechanism. Refines Stage-1 outputs to eliminate noise and stabilize final decisions.
* **Modern Dashboard:** Dynamic dark-mode UI featuring real-time confidence bars and an intelligence timeline.

---

##  Technical Pipeline

The system transforms raw audio into a final command through the following stages:

1.  **Signal Conditioning:** 100Hz-6000Hz Band-pass filtering, normalization, and 0.1s fixed padding.
2.  **Stage 1:** 1.0s window length and 0.1s hop size processing via CNN models (MEL/MFCC features).
3.  **Stage 2:** Aggregation of Stage-1 predictions. Final decision-making via **Majority Voting** (Hybrid mode) or **NLP Cosine Similarity** (Stable mode).
4.  **Evaluation:** Real-time **Response Time (RT)** measurement and automatic **Ranking Score** calculation.

---

## Performance Metrics & Ranking

System success is measured by the official ranking formula, optimizing the balance between accuracy and speed:

$$Score = \frac{Accuracy_{TR} \times Accuracy_{EN}}{ResponseTime_{TR} \times ResponseTime_{EN}}$$

* **Training Protocol:** All models were trained using `Random Seed = 47` and an `80%-20%` stratified split.
* **Execution:** The system operates with millisecond-level latency (Response Time) in real-time environments.

---

##  Project Structure

* `Dataset_For_CNN/`: Raw audio recordings for training and testing.
* `models/`: Pre-trained CNN models (.h5), scalers, and label encoders.
* `results/`: CSV reports containing accuracy, F1-score, and complexity metrics.
* `main_inference.py`: File-based (Playback) analysis interface.
* `main_realtime.py`: Real-time microphone analysis interface.

---

## Installation

Install the required dependencies:
`pip install tensorflow keras librosa numpy pandas sounddevice joblib gensim scikit-learn`

---

## ğŸ“ Developer

* **Erdem Tosun**
